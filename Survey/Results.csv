"What is your current job title? (Developer, Researcher, ... students may indicate degree: PhD, Master) ",Which LLMs do you mostly use? Select as many as you use. You can enter one manually if it's not on the list.,"Aside from Python, which programming languages did you generate code for using LLMs?","How often do you encounter mistakes in LLMs generated code you use? 

Those mistakes can be anything, from code that won't compile (variable not defined, function that does not exist) to more silly choice from the LLMs (multiples If condition checking the same thing or casting back and forth a variable for no reason).","When you encounter mistakes in LLMs generated code, how complex is fixing those issues?","To fix those issues, how do you proceed?","Hallucinated objects:
LLMs hallucination such as using a function or built-in type that does not exist and was not defined previously but that the LLMs consider present within the context.
In the example below, the LLM (besides not doing what the docstring asks), uses a function named ""find_path_to_glob"" which is not defined in the context.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Silly Mistakes

Mistakes such as redundant conditions or casting for no reason. The change won't introduce a bug on its own but it can easily lead to it. 

In the example below, the LLM repeats the same functionality inside both branches of the 'if...else...' structure. This does not cause a bug, but has little usefulness in the code and can even lead easily to a mistake if the user tries to expand the code.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Prompt-biased

When the LLM relies too much on an example or words given in the prompt when implementing the function which hampers the generated code generalization.
In the example below, the LLM relies too much on the example given in the docstring. By doing so, it generates a code that only works on a polygon with 4 vertices (just like in the example). Yet, the function should generalize to any number of vertices.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Missing Corner Case

When the code is very similar to what was expected, yet the LLM might miss some corner case or neglect a part of the information given by the prompt.
In the example below, the expected code is given at the top and the LLM generated code is at the bottom. To generate the code, the LLM only had access to the function signature and the small docstring in between """""". As one can see, the LLM code is very similar to the expected one, but it's missing some additional parts that would have been expected. Nonetheless, the code is still functional with regard to the information given.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Wrong Input Type

When the LLM uses an incorrect input type in some function.
In the example below, the LLM generated code uses the Python function 'min' on 'class_' which is a class object. The function 'min' can't handle class objects as input and so an error is raised.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Wrong Attribute

When the LLM uses a wrong attribute for an object or module. 

In the example below, the LLM generated code for parsing an .xml file. The LLM generated a method attribute named 'xpath' which does not exist for an xml object, raising an error.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Incomplete Generation

When there is no code generated, simply a ""pass"" or the code generation is not finished either because the LLM does not ""know"" what to put next or because of a token limit.

In the example below, the LLM stops the generation of the code while the function code is clearly not finished (symbolized with a the final '#').","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Non-Prompted Consideration

When the LLM adds something to the code which is not asked in the prompt to the point it leads to an error directly or indirectly. 

In the example below, the LLM processes the prompt currently, parsing the ArgumentParser object, until it suddenly decides to sort the result using the ""sorted"" function. This was not asked in the prompt and leads to an error since the different flags of ArgumentParser won't be in the initial order.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Synthax Error

When the LLM code contains syntax errors such as missing parenthesis, indentation error, function of a library not properly called. ..

In the example below, the LLM generated a code where the parenthesis is missing in function signature. This will obviously raise a bug.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Misinterpretation

When the LLM generated code is false and is not in the direction of addressing the prompt (i.e. it's quite different from what was intended in the prompt).

In the example below, the expected code is given at the top and the LLM generated code is at the bottom. To generate the code, the LLM only had access to the function signature and the small docstring in between """""". One can see that, on top of forgetting one of the function parameters and changing the default value of another one (alphabet), the generated code is way different compared to the given prompt.","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Diagnosing]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Complexity]","How do you assess diagnosing, severity, and fixing of such a bug? 

If you never experienced such bug, please answer based on your understanding using the previous snippet as an example for the bug type. [Fixing]",Comments?,"Thank you very much for your answers, it is very much appreciated !

If you have any additional comments/remarks/suggestions please let us know below."
PhD Student,Codex (Copilot);ChatGPT;LLama;Code Bison (Google),SQL,Often,Medium,Manually modifying the code,3,2,1 (Easy/Trivial),2,,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,4,3,4,4,,3,4,4,3,,2,4,2,2,,5,2,1 (Easy/Trivial),3,"Easy to diagnose when using an IDE with real time code checking, but can be difficult to fix because I often need to dig up library documentation to find the correct object name.",3,4,2,3,,4,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,1 (Easy/Complex),3,2,,2,3,4,4,,"There is a difference in LM-generated code quality between using an in-IDE plugin such as copilot, and using a browser-based tool such as chat gpt or google bard. I find that copilot has more of a tendency to recommend code that I don't need, or code that is redundant; though its strength lies in its contextual awareness of the program, so it can often infer blocks of code without an explicit prompt. On the other hand, the browser-based tools seem better at providing accurate and better quality blocks of code, but the quality depends on the descriptiveness of the prompt."
Highschool student (senior),Codex (Copilot),C++;Java,Sometimes,Easy,"Find a bug, trace back to the origin, understand the intent and method created by the llm, find a working or better solution",4,1 (Easy/Trivial),2,2,Most often time after providing a header or function definition the model is able to correctly create the method or function ,3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),Usually adding comments outlining the expected result in a logic tree or if/else chain solves these issues,4,2,2,2,"Usually a result of poor documentation on the package end, bad user instructions, or utilizing outdated package documentation",4,2,1 (Easy/Trivial),1 (Easy/Trivial),"Usually easy to fix by segmenting instructions or outlining a specific use case, it can also be fixed by making the model generate additional options but this commonly results in unrelated cases being considered ",3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),Quite often this can be fixed by manual changes or specifying logic in a comment,4,2,1 (Easy/Trivial),2,"Almost always a result of utilizing outdated documentation for external packages, or with custom packages, a result of bad user prompts or poor class documentation ",3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),Usually limiting generation to a specific fragment of a snippet will solve this and helps keep the model on track with your idea,2,2,1 (Easy/Trivial),1 (Easy/Trivial),A manual fix or adding specific instruction can solve these issues,4,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),Almost always this can be solved by making the model finish the line from its insert and on. This is usually the result of a model trying to insert code and incorrectly removing certain text.,3,1 (Easy/Trivial),1 (Easy/Trivial),2,Usually more outlining or instructions can be added after a docstring to help guide the model.,
Researcher,Codex (Copilot);ChatGPT,Java,Occasionally,Medium,google + manually,1,2,2,2,"Often, I will test quickly by checking if the code is compilable or not, or come up with a few test cases. If I cannot diagnose after a few tries, I will abandon the output and seek help from google. In short, I won't spend too much time (more than 1 minute) to try to fix.",1,3,1 (Easy/Trivial),1 (Easy/Trivial),"When I use LLM, I always expect I need to modify the output more or less for adaption purpose. So I will often spend sometime to quick check which part I need to modify, so sily mistakes are usually easy to notice.",2,1 (Easy/Trivial),3,5 (Hard/Complex),,3,5 (Hard/Complex),3,2,,2,4,4,2,,4,1 (Easy/Trivial),2,2,"Since it will raise an error, so it won't be hard for me to aware of it as I always need to run the code. Fix usually involve with reading official documentation.",1,1 (Easy/Trivial),2,5 (Hard/Complex),"I typically use it in method-level, so it's rare to exceed to the token output limit.",3,3,3,2,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,4,4,4,,My experience is mostly based on when I use Codex.
PhD,Codex (Copilot);ChatGPT,JavaScript,Often,Medium,Manually modifying the code,2,1 (Easy/Trivial),3,2,,3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,1,1 (Easy/Trivial),3,3,,2,3,3,2,,2,2,2,2,,4,1 (Easy/Trivial),2,2,,4,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),Is it a problem?,2,1 (Easy/Trivial),2,2,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,2,1 (Easy/Trivial),2,3,,
"Student, Bachelor's Degree","Codex (Copilot);ChatGPT;LLama;claude, bard","Java;JavaScript;ocaml, rust",Occasionally,Medium,Combination of both,4,1 (Easy/Trivial),1 (Easy/Trivial),3,,3,3,2,2,,4,1 (Easy/Trivial),3,4,,3,4,3,3,,1,2,2,4,,2,3,2,3,,1,1 (Easy/Trivial),1 (Easy/Trivial),2,,3,2,1 (Easy/Trivial),1 (Easy/Trivial),,1,1 (Easy/Complex),3,3,,3,1 (Easy/Trivial),3,3,,love u
PhD,ChatGPT,Python,Often,Easy,Manually modifying the code,4,1 (Easy/Trivial),2,3,,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,1,1 (Easy/Trivial),2,2,,1,3,2,1 (Easy/Trivial),,1,1 (Easy/Trivial),2,2,,4,1 (Easy/Trivial),2,3,,3,1 (Easy/Trivial),2,3,,1,1 (Easy/Trivial),2,2,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,1,2,2,2,,
Postdoctoral Researcher,Codex (Copilot);ChatGPT,C;JavaScript;HTML,Occasionally,Medium,Manually modifying the code,3,1 (Easy/Trivial),2,2,,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,4,2,2,3,,4,4,4,4,,2,3,2,3,,2,2,2,3,,3,1 (Easy/Trivial),2,3,,3,4,3,2,,2,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),Very rare with the state-of-the-art models.,3,3,4,4,,
Researcher,ChatGPT;LLama,Java;JavaScript,Occasionally,Medium,Combination of both,2,1 (Easy/Trivial),3,3,,1,2,2,1 (Easy/Trivial),,1,3,4,5 (Hard/Complex),,2,4,4,4,,2,2,2,2,,3,3,3,3,,4,3,4,4,,4,4,5 (Hard/Complex),5 (Hard/Complex),,3,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,2,3,3,3,,
PhD Researcher,Codex (Copilot);ChatGPT,C;Java;JavaScript;Svelte,Sometimes,Medium,Manually modifying the code,2,1 (Easy/Trivial),2,2,"The fact that this is the model output indicates that the common way of solving such a problem is to decompose the problem into two functions, i.e., to define both make_find_paths() and find_path_to_glob(). Inadvertently, the model output indicates a way to factor your code into smaller pieces.",2,1 (Easy/Trivial),1 (Easy/Trivial),4,"Fixing is more difficult but you really have to think... why would the model produce this output? Am *I* doing something unusual? The possible fixes could be many, and there are many different ways to go about it. It's more of a ""sit back and think"" kind of fix instead of mindlessly removing the silly mistake.",1,1 (Easy/Trivial),3,4,I would just manually write the code if the LLM has difficulty with the prompt. No sense wasting time to prompt engineer when I could use that same time writing code that I *think* will work.,4,4,3,5 (Hard/Complex),"It is a risk to become complacent to LLM code generation, because sometimes code looks reasonable (in this case), but you might be unaware of all the ways it could fail. For example, I would very much forget about IPv6 (don't we all? :)) and miss that corner case myself. So it is both my lack of knowledge and implicitly trusting the LLM output that can make this such an insidious bug to diagnose and solve.",2,3,3,3,"This is a case-by-case basis. It would be easier to fix in a language with static typing, since the IDE would tell you that it's wrong. However, sometimes things type-check and are still wrong. Either way, this kind of mistake could be really easy to solve or really difficult to solve. I would recommend using static-typing (yes, even in Python) instead of trying to make LLMs magically solve all these problems.",3,3,3,3,"Like my earlier answer, this is mostly solved by using static typing. If the LLM output generates a bogus attribute, the IDE will tell you. You can then fix it manually. But if you don't have static typing, you have to wait to discover it until runtime, which might be a nightmare to debug.",3,4,2,1 (Easy/Trivial),"This happened to me recently, and I was EXTREMELY CONFUSED. I was like... why am I getting weird errors? But it's because it generated half of a function that HAPPENED to be syntactically correct, and it made the next function reference variables that weren't in the right scope. It took me a while to read the entire code to realize... wait, this function is not complete... I should finish it... and then my errors went away. Never become complacent with the LLM output.",2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),"Just delete the bogus code. Also, why is the indentation in this example off?",3,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),"As an experienced Python programmer, there aren't many syntax errors that I can't solve right away (there are a few, but that means my code has gotten too complex). It's easy to solve this manually.",3,3,3,3,"It depends on if you know what you are expecting the code to look like. If so, this is easy to spot, and probably you're better off manually writing the code. I have tried to prompt engineer, but I find that it's a waste of my time. Sometimes, you will get code generated that misinterprets the prompt, but maybe you are not aware of what the generated solution looks like so you have to read the generated code intently, or figure out the library calls that are generated to understand that it misunderstood the prompt.",
PhD,Codex (Copilot);ChatGPT,"JavaScript;Vue, HTML, CSS, Shell",Occasionally,Easy,Combination of both,3,1 (Easy/Trivial),1 (Easy/Trivial),2,"Sometimes, the LLM would generate functions that are deprecated. It is not necessarily hallucinating, it was just trained on an older version of the python package you are using.",1,2,2,2,ChatGPT is very clever in organizing code and making it modular so I didnt experience these kinds of situations.,2,1 (Easy/Trivial),3,3,,2,3,3,2,,2,2,2,2,,4,2,2,2,,4,1 (Easy/Trivial),1 (Easy/Trivial),4,,3,4,4,2,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,4,4,4,,I filled out the survey to the best of my knowledge. Hope it is helpful for your research. We did a study to assess ChatGPT's code-generating capabilities. You will find it interesting to read. You are more than welcome to use our findings in your research. https://arxiv.org/abs/2311.02640
Master,"Codex (Copilot);ChatGPT;Claude, Bing Chat",JavaScript,Often,Easy,Combination of both,5,2,1 (Easy/Trivial),1 (Easy/Trivial),"I think it can be resolved easily by asking to generate code continuously. LLM cound define the undefined function. For me, I thought it's not the hallucination, it just haven't finished generation yet.",4,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),"In this case, I will add more detailed instruction.",4,1 (Easy/Trivial),2,2,"In this case, I will make the instruction more explicit, such as explicitly state that the example case is just an example.",5,4,3,2,"As usual, the instruction lacks the detailed specification of expected behavior.",4,4,4,3,,4,3,2,3,It can be more difficult to fix or can require more larger edit to fix if we cannot find the existing function that the LLM intended to use.,5,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),"It can be difficult to address if the reason is token limit, but I usually ask the LLM again to generate continuously.",4,3,3,2,This example is easy. But I have observed some difficult cases that non-requested behavior is in the middle of the generated code.,2,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),I have encountered some errors that some functions not properly called but never encountered errors of missing parenthesis.,3,1 (Easy/Trivial),1 (Easy/Trivial),3,,
Researcher,Codex (Copilot);ChatGPT;LLama,Java;Python,Occasionally,Medium,Combination of both,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,3,3,3,3,,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,3,2,2,2,,3,1 (Easy/Trivial),2,1 (Easy/Trivial),,4,1 (Easy/Trivial),4,3,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,1 (Easy/Trivial),4,4,,
Master,Codex (Copilot);ChatGPT,C;C++;Java;JavaScript,Sometimes,Medium,Combination of both,4,1 (Easy/Trivial),2,2,,4,1 (Easy/Trivial),2,2,,5,1 (Easy/Trivial),3,3,,5,2,3,3,,4,2,3,2,,3,1 (Easy/Trivial),2,2,,4,1 (Easy/Trivial),2,3,,3,2,3,3,,2,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,1 (Easy/Trivial),3,3,,
High school student,ChatGPT,Go,Always,Easy,Manually modifying the code,3,1 (Easy/Trivial),2,3,"The hardest part about this is finding out what the function would do, but in most cases it would be quite an easy function to re-create.",4,1 (Easy/Trivial),1 (Easy/Trivial),2,"This is just more tedious than anything else, and I usually immediately spot mistakes like these.",4,3,3,3,"I've had this happen with a probability calculation function I had put in to test if the LLM could write better code than I could, and it wasn't fun to debug.",2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,4,1 (Easy/Trivial),2,3,,4,2,1 (Easy/Trivial),2,"I tend to have this when I try to use a library that either has changed a lot over a short period of time, or that I don't know a lot about.",4,1 (Easy/Trivial),2,2,"This is one of the issues that really makes AI feel like a chore to use for help when coding, and it has really put me off from using it.",3,2,2,2,,3,1 (Easy/Complex),1 (Easy/Complex),2,,3,1 (Easy/Trivial),2,3,,"The last time I properly used AI to generate code for me was quite a while ago, and I've honestly just given up on the idea and have reverted back to StackOverflow or other random forums for help."
PhD,ChatGPT,Rust,Often,Hard,Combination of both,5,1 (Easy/Trivial),3,1 (Easy/Trivial),"With the help of IDE, I could easily diagnosing this bug from red underline or the color of the function (purple in this case). It is then intuitively to see that there must be something wrong inside the code.",1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),I hardly overcome this mistake in my experience.,4,1 (Easy/Trivial),1 (Easy/Trivial),5 (Hard/Complex),"I face this problem when docstring given too much examples, and the prompt require LLMs to pass at least all the test cases. Then, there might be small chances to encounter such mistake. From both LLM and coder perspectives, it is easy to be diagnosed, but fixing such mistake, might need LLMs to pay more attention on the context in the docstring.",5,5 (Hard/Complex),5 (Hard/Complex),5 (Hard/Complex),"It is very depending on the evaluation test case set. From its short natural language description, like docstring, it's hard to cover all its possible corner cases. This is an interesting mistake and worth to be explored in the future.",5,5 (Hard/Complex),4,1 (Easy/Trivial),"This often happens when the temperature of the LLM is high (for example, using ChatGPT). In this case, the mistake is not ridiculous enough to generate some random, unrelated token. From my experience, such bugs are logical bugs, which might not affect the code's compiability, but heavily affect its correctness. As a developer, we could also have such mistake, and spend tons of time to locate the bug, but fix it promptly. ",4,3,3,5 (Hard/Complex),"Fixing such bug need the knowledge of standard library, public library, and sometimes the third-party library, which is quite tricky to fix for both LLMs and Human. For LLMs, based on its training data (memory), such wrong token is the best answer. Even let LLMs to do the code generation again, such mistake still might exist. For human, once we read the API document, then we could know how to use this library (and its functions).",5,1 (Easy/Trivial),1 (Easy/Trivial),5 (Hard/Complex),"This is mainly because of the response reaches the max token limitation of LLMs. Fingercross for better LLMs in the future. Otherwise, we have to simpliy the input prompt or decomposite the code generation task.",5,5 (Hard/Complex),5 (Hard/Complex),5 (Hard/Complex),This is also a mistake that beause of LLMs 'strong memory'. Such mistakes are tricky to be found at the first glance if it is still runable. Fixing such error also need tto pay more attention on the context of the code generation task.,3,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),"The 'typo' of LLMs is easy to be detected from the running or compiling the code. It does occur a lot when the temperatue is high, but rare for normal temoeratures.",5,5 (Hard/Complex),5 (Hard/Complex),5 (Hard/Complex),This might be attribute to the complexity of the prompt given. Decomposing the prompt or re-claim the prompt would be great.,
Developer,Codex (Copilot);ChatGPT,C++;JavaScript;C#,Often,Easy,Combination of both,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),"As I work on the generated code, I might clarify a variable name, or add an extra comment, then the next generated code is probably correct. ",1,2,2,2,,3,2,2,2,,4,3,1 (Easy/Trivial),1 (Easy/Trivial),,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,4,2,1 (Easy/Trivial),1 (Easy/Trivial),,3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),"I just don't tab-complete these suggestions. There are so many, but easily ignored. ",3,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),"They are common and often in the same context, so fixes become automatic as we work with the LLM",3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,
PhD,Codex (Copilot);ChatGPT,JavaScript;Latex,Sometimes,Medium,Combination of both,2,1 (Easy/Trivial),1 (Easy/Trivial),3,,3,2,2,2,,3,2,2,4,,4,4,4,4,,3,4,3,2,,4,2,3,3,,4,1 (Easy/Trivial),1 (Easy/Trivial),5 (Hard/Complex),,3,3,3,3,,2,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,2,4,4,4,,
Developer and Startup Founder,Codex (Copilot);ChatGPT,"SQL, Cypher",Sometimes,Easy,Combination of both,1,1 (Easy/Trivial),1 (Easy/Trivial),5 (Hard/Complex),"I've had references to functions that don't exist. Sometimes they are functions from a past version, or from an enterprise edition of a library I don't have. Never anything this extreme.",1,2,1 (Easy/Trivial),3,,4,1 (Easy/Trivial),4,1 (Easy/Trivial),"If the developer has a specific use case in mind, this would happen rather naturally. That's why i say its complex, as you need to be coding without a specific problem in mind to do it ""right""",4,4,5 (Hard/Complex),2,"I found I need to improve my prompts or create prompts specific for air, checking, or Edge cases. I actually would not expect LLM to generate error proof code for me.",2,4,4,1 (Easy/Trivial),"My personal level of experience and coding is quite low, I don't have a computer, science background and come from a mechanical engineering background. These types of issues are something that I personally struggle with a lot as a coder and would not be able to pick it out on my own",2,5 (Hard/Complex),4,1 (Easy/Trivial),"For fixing these types of issues given my experience and how I use LLM's I would actually use the LLM itself to fix the error. for that reason I say it's easy, but if I had to fix it myself, I would have to go into documentation, and would not necessarily know how to do it",1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,3,2,1 (Easy/Trivial),,1,1 (Easy/Complex),2,1 (Easy/Complex),,1,4,3,4,"In my opinion, this prompt is far too simple for what I believe to be a much more complex request",
bachelor student ,Codex (Copilot);ChatGPT,C;C#,Sometimes,Medium,Manually modifying the code,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,3,2,2,3,,2,1 (Easy/Trivial),2,3,,2,4,4,4,,2,3,3,4,,4,2,3,4,,3,1 (Easy/Trivial),2,2,,4,3,4,4,,1,3,2,4,,4,3,4,5 (Hard/Complex),,"Code logic error is significant e.g. writing complex user-defined logic, which may be categorized into ""misinterpretation "" but I think there are some differences."
Research/Data Scientist ,Codex (Copilot);ChatGPT,C,Often,Medium,Combination of both,3,1 (Easy/Trivial),2,2,Fixing is not always trivial as sometimes the function is difficult to implement.,2,1 (Easy/Trivial),2,1 (Easy/Trivial),I have seen it done by pro devs multiple times...,4,1 (Easy/Trivial),2,3,I am going crazy when it happens.,4,2,3,3,,4,2,2,2,,3,1 (Easy/Trivial),2,2,,3,1 (Easy/Trivial),1 (Easy/Trivial),2,,4,1 (Easy/Trivial),2,3,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,2,2,3,,"Some of the errors are related to misunderstanding requirements, so it's difficult to decide on a meaningful complexity scoe. I believe that communication is always a challenge. Cool survey though."
Undergraduate ,ChatGPT;LLama;Deepseek Coder,C++;Java,Often,Medium,Combination of both,1,1 (Easy/Trivial),3,4,,2,2,1 (Easy/Trivial),2,,4,4,2,4,,1,2,1 (Easy/Trivial),2,,4,2,2,2,,4,2,2,3,,4,2,4,4,,1,2,2,2,,2,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,2,2,2,2,,
PhD,ChatGPT,"C++;Javascript, React",Often,Medium,Manually modifying the code,3,1 (Easy/Trivial),2,3,,2,2,1 (Easy/Trivial),2,,3,3,2,4,,2,4,3,3,,5,1 (Easy/Trivial),2,2,,5,3,3,3,,2,2,3,4,,2,4,3,3,,3,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,3,4,4,,
Data Scientist ,ChatGPT;LLama,R,Often,Medium,Combination of both,1,1 (Easy/Trivial),2,3,,4,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,4,1 (Easy/Trivial),2,2,,5,3,2,2,,4,2,2,2,,4,3,2,2,,4,1 (Easy/Trivial),2,2,This one is weird- I often get ‘your function to do x here:’ as a comment,3,3,3,3,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,2,2,3,3,,
CTO,Codex (Copilot);LLama,JavaScript,Often,Medium,Combination of both,2,1 (Easy/Trivial),1 (Easy/Trivial),4,,4,3,1 (Easy/Trivial),1 (Easy/Trivial),,2,2,2,3,,4,4,4,4,,2,1 (Easy/Trivial),2,4,,3,2,2,4,,1,1 (Easy/Trivial),1 (Easy/Trivial),4,,3,3,3,3,,1,1 (Easy/Complex),1 (Easy/Complex),4,,2,1 (Easy/Trivial),1 (Easy/Trivial),4,,"For every category, the answer on ""difficulty to diagnose"" really boils down to ""it depends"". e.g. a missing function is a minor thing if the missing function is trivial to write or generate. And a major thing if the hard part of the problem is in the function that wasn't generated."
Postdoc researcher,Codex (Copilot);ChatGPT,C++,Always,Hard,Manually modifying the code,4,2,1 (Easy/Trivial),5 (Hard/Complex),,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,5,2,2,5 (Hard/Complex),,3,4,3,4,,3,3,2,3,,2,1 (Easy/Trivial),1 (Easy/Trivial),3,,2,1 (Easy/Trivial),1 (Easy/Trivial),5 (Hard/Complex),,4,4,2,4,,5,2,1 (Easy/Complex),4,,5,3,4,5 (Hard/Complex),,
Master's Student,ChatGPT,C++,Often,Medium,Combination of both,2,1 (Easy/Trivial),1 (Easy/Trivial),3,,2,2,2,3,,4,1 (Easy/Trivial),2,4,,3,4,4,4,,4,1 (Easy/Trivial),2,4,,4,3,5 (Hard/Complex),4,,4,1 (Easy/Trivial),1 (Easy/Trivial),2,Normally asking the LLM to continue generating solves the problem,3,4,4,4,,1,2,1 (Easy/Complex),2,,2,4,4,3,,
PhD,Codex (Copilot);ChatGPT;CodeGen,Only Python,Often,Very Hard,Combination of both,4,1 (Easy/Trivial),1 (Easy/Trivial),4,The fix is a bit difficult as I have to add the functionality.,3,1 (Easy/Trivial),1 (Easy/Trivial),2,"The fix is easy, i just need to delete duplicates. ",4,1 (Easy/Trivial),1 (Easy/Trivial),4,"This is a bit challenging to fix, this is kinda a logical bug. ",1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),I don't understand why this is a corner case.,5,1 (Easy/Trivial),2,2,Type related issues are often easy to fix (depending on expertise level). ,5,2,2,2,This is an API Misuse. The fix also depends on how the developer knows the documentation.,4,1 (Easy/Trivial),4,4,This is a bit difficult because I have to add logic. ,2,4,4,4,All three tasks are difficult for this one.,5,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,3,3,4,,"I leave this comment based on my own background. I am working on API Level Fuzz Testing. In general, LLMs are prone to a high rate of invalid/failed test cases, yet successful in terms of finding new bugs. In general, using LLM is a win huge loss is tiny scenario. Please let me know if I can further help you, though I am not very good at using LLMs. "
"PhD, working in neuroscience",Codex (Copilot);ChatGPT,no other language,Sometimes,Trivial,Manually modifying the code,4,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,2,2,2,"I rarely use Copilot to write whole functions for me, so it rarely has to rely on longer prompts. I often do the other way around and use Copilot to help me write the docs.",1,3,2,1 (Easy/Trivial),,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,1 (Easy/Trivial),2,2,,1,3,2,1 (Easy/Trivial),,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,3,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,
Frontend Developer,ChatGPT;LLama,JavaScript,Occasionally,Medium,Manually modifying the code,5,2,4,4,,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,2,2,2,,3,2,2,2,,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,2,2,2,,2,2,2,1 (Easy/Trivial),,2,2,2,1 (Easy/Trivial),,4,3,3,4,,2,2,2,2,,
Lecturer,ChatGPT,C;C++,Sometimes,Medium,Combination of both,4,4,1 (Easy/Trivial),4,"I think the bugs are relate to the task/scenario of using LLMs. In most of my usage scenarios, I generate code with LLM based on existing code. It could be different from letting LLMs generate code from scratch. Also, I think the diffculty of fixing some types of bugs relates to the purpose of the code.",4,1 (Easy/Trivial),3,4,,2,4,4,4,,4,4,4,4,,3,4,4,4,,3,4,4,4,,3,1 (Easy/Trivial),3,4,,3,3,3,3,,2,2,2,2,,2,4,4,4,,
Developer,Codex (Copilot);ChatGPT,JavaScript;Dart,Sometimes,Medium,Combination of both,3,1 (Easy/Trivial),2,4,,2,3,1 (Easy/Trivial),1 (Easy/Trivial),,4,3,3,3,,4,3,2,2,,1,3,3,3,,4,2,2,2,,4,2,3,4,,2,4,2,2,,1,1 (Easy/Complex),1 (Easy/Complex),2,,2,3,2,4,,
Developer,ChatGPT;LLama,SQL,Sometimes,Medium,Combination of both,3,2,3,3,,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,4,2,3,4,,4,3,3,4,,2,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,2,2,2,2,,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,1,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,3,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,2,2,2,3,,
Developer,Codex (Copilot);ChatGPT,C;JavaScript,Often,Medium,Combination of both,1,1 (Easy/Trivial),1 (Easy/Trivial),3,,3,3,2,4,,5,3,5 (Hard/Complex),5 (Hard/Complex),,5,4,3,4,,3,3,4,5 (Hard/Complex),,3,3,4,5 (Hard/Complex),,1,2,2,4,Very rare but means you need to split into several prompts,1,2,2,2,,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,3,3,3,3,,"There is one situation that happens very frequently and almost always LLMs mess up. Specially ChatGPT (free), it is when you try to compose two prompt results in a quite evident way. Like ""now use (integrate) function (result) f1 in f2"". This a very important logical programming practice, in most of the cases LLMs fail to find the proper logical way to achieve the desired result, because are unable to keep track of the conversional logic of their own results. At the end I always end up composing the logic myself, very tedious."
PhD,Codex (Copilot);ChatGPT;LLama,C;C++;Java;JavaScript,Sometimes,Medium,Combination of both,1,1 (Easy/Trivial),4,4,I think it depends a lot on the richness of the language - this can be either an obscure library reference or just a hallucination ,5,1 (Easy/Trivial),1 (Easy/Trivial),1 (Easy/Trivial),,3,1 (Easy/Trivial),1 (Easy/Trivial),2,,4,5 (Hard/Complex),5 (Hard/Complex),2,,1,3,2,1 (Easy/Trivial),,4,4,4,3,,1,4,4,4,"This depends a lot on the cutoff point, sometimes there may be no sign that it is incomplete unless one checks the functionality",1,2,3,1 (Easy/Trivial),,1,1 (Easy/Complex),1 (Easy/Complex),1 (Easy/Complex),,4,3,3,3,,
